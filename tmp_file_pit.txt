__doc__ = """
The `calibration` package provides tools for fitting model parameters to market data.

This includes high-performance, vectorized implied volatility solvers, tools for
estimating historical parameters, and the core `Calibrator` class that ties
these components together to perform model calibration against option chains.
"""

# Core calibration class
from .calibrator import Calibrator

# Parameter fitting utilities
from .fit_jump_parameters import fit_jump_params_from_history
from .fit_market_params import fit_rate_and_dividend

# Volatility surface representation
from .iv_surface import VolatilitySurface

# Helper for selecting the best pricing technique
from .technique_selector import select_fastest_technique

# --- High-performance, vectorized implied volatility solvers ---
# The BSMIVSolver was moved to its own file, let's assume 'vectorized_bsm_iv.py'
# or similar. If it's in 'vectorized_iv_solver.py', adjust the import.
from .bsm_iv_solver import BSMIVSolver
from .vectorized_integration_iv import VectorizedIntegrationIVSolver


# Define the public API for the calibration package
__all__ = [
    "Calibrator",
    "fit_jump_params_from_history",
    "fit_rate_and_dividend",
    "VolatilitySurface",
    "select_fastest_technique",
    "BSMIVSolver",
    "VectorizedIntegrationIVSolver",
]

--
import numpy as np
from scipy.stats import norm

from quantfin.atoms.option import Option, OptionType
from quantfin.atoms.stock  import Stock
from quantfin.atoms.rate   import Rate
import pandas as pd
class BSMIVSolver:
    """
    A high-performance, vectorized Newton-Raphson solver for Black-Scholes
    implied volatility.
    """
    def __init__(self, max_iter: int = 20, tolerance: float = 1e-6):
        self.max_iter = max_iter
        self.tolerance = tolerance

    def solve(self, target_prices: np.ndarray, options: pd.DataFrame, stock: Stock, rate: Rate) -> np.ndarray:
        """
        Calculates implied volatility for a whole array of options at once.
        """
        S = stock.spot
        r = rate.rate
        q = stock.dividend
        
        K = options['strike'].values
        T = options['maturity'].values
        is_call = (options['optionType'].values == 'call')

        # Initial guess for volatility
        iv = np.full_like(target_prices, 0.20)

        for _ in range(self.max_iter):
            # --- Vectorized BSM Price and Vega ---
            sqrt_T = np.sqrt(T)
            d1 = (np.log(S / K) + (r - q + 0.5 * iv**2) * T) / (iv * sqrt_T)
            d2 = d1 - iv * sqrt_T
            
            # Price
            call_prices = S * np.exp(-q * T) * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)
            put_prices = K * np.exp(-r * T) * norm.cdf(-d2) - S * np.exp(-q * T) * norm.cdf(-d1)
            model_prices = np.where(is_call, call_prices, put_prices)
            
            # Vega
            vega = S * np.exp(-q * T) * sqrt_T * norm.pdf(d1)
            
            # --- Newton-Raphson Step ---
            error = model_prices - target_prices
            
            # If error is small enough, we're done
            if np.all(np.abs(error) < self.tolerance):
                break
            
            # Update guess (avoid division by zero)
            iv = iv - error / np.maximum(vega, 1e-8)

        return iv


import numpy as np
from scipy.optimize import minimize, minimize_scalar, differential_evolution
from typing import List, Dict, Any
import pandas as pd

from quantfin.calibration.technique_selector import select_fastest_technique
from quantfin.models.base                import BaseModel
from quantfin.atoms.option               import Option, OptionType
from quantfin.atoms.stock                import Stock
from quantfin.atoms.rate                 import Rate



class Calibrator:
    def __init__(self, model: BaseModel, market_data: pd.DataFrame, stock: Stock, rate: Rate):
        self.model = model
        self.market_data = market_data
        self.stock = stock
        self.rate = rate
        self.technique = select_fastest_technique(model)
        print(f"Calibrator using '{self.technique.__class__.__name__}' for model '{model.name}'.")

    def _objective_function(self, params_to_fit_values: np.ndarray, params_to_fit_names: List[str], frozen_params: Dict[str, float]) -> float:
        # 1. Reconstruct the full parameter dictionary
        fitted_params = dict(zip(params_to_fit_names, params_to_fit_values))
        current_params = {**frozen_params, **fitted_params}
        
        print(f"  Trying params: { {k: f'{v:.4f}' for k, v in current_params.items()} }", end="")

        try:
            temp_model = self.model.__class__(params=current_params)
        except ValueError as e:
            print(f" -> Invalid params ({e}), returning large error.")
            return 1e12

        # 2. Calculate model prices and sum squared errors
        total_error = 0.0
        for _, row in self.market_data.iterrows():
            option = Option(
                strike=row['strike'], maturity=row['maturity'],
                option_type=OptionType.CALL if row['optionType'] == 'call' else OptionType.PUT
            )
            # Pass all current params as kwargs for techniques that need them (e.g., Heston's v0)
            model_price = self.technique.price(option, self.stock, temp_model, self.rate, **current_params).price
            market_price = row['marketPrice']
            total_error += (model_price - market_price)**2
            
        print(f"  --> Total Error: {total_error:.4f}")
        return total_error

    def fit(self, initial_guess: Dict[str, float], bounds: Dict[str, tuple], frozen_params: Dict[str, float] = None) -> Dict[str, float]:
        frozen_params = frozen_params or {}
        params_to_fit_names = [p for p in initial_guess if p not in frozen_params]
        
        print(f"Fitting parameters: {params_to_fit_names}")

        if not params_to_fit_names:
            print("No parameters to fit. Returning frozen parameters.")
            return frozen_params

        fit_bounds = [bounds.get(p) for p in params_to_fit_names]
        if any(b is None for b in fit_bounds):
            raise ValueError(f"Bounds must be provided for all fitted parameters: {params_to_fit_names}")

        initial_values = [initial_guess[p] for p in params_to_fit_names]

        # --- Dispatch to the best optimizer ---
        if len(params_to_fit_names) == 1:
            scalar_fun = lambda x: self._objective_function(np.array([x]), params_to_fit_names, frozen_params)
            result = minimize_scalar(fun=scalar_fun, bounds=fit_bounds[0], method='bounded')
            final_params = {**frozen_params, params_to_fit_names[0]: result.x}
            print(f"Scalar optimization finished. Final loss: {result.fun:.6f}")
        else:
            result = minimize(
                fun=self._objective_function,
                x0=initial_values,
                args=(params_to_fit_names, frozen_params),
                method='L-BFGS-B',
                bounds=fit_bounds,
                options={'maxiter': 200, 'disp': False}
            )
            final_params = {**frozen_params, **dict(zip(params_to_fit_names, result.x))}
            print(f"Multivariate optimization finished. Final loss: {result.fun:.6f}")

        return final_params

import numpy as np
import pandas as pd
from scipy.stats import kurtosis, skew

def fit_jump_params_from_history(log_returns: pd.Series, threshold_stds: float = 3.0) -> dict:
    """
    Estimates jump parameters and diffusion volatility from historical returns.
    """
    print("Fitting jump parameters from historical returns...")
    
    std_dev = log_returns.std()
    jump_threshold = threshold_stds * std_dev
    
    diffusion_returns = log_returns[abs(log_returns) < jump_threshold]
    jump_returns = log_returns[abs(log_returns) >= jump_threshold]
    
    # Annualize daily std dev by multiplying by sqrt(252 trading days)
    sigma_est = diffusion_returns.std() * np.sqrt(252)

    if len(jump_returns) > 2:
        lambda_est = len(jump_returns) / len(log_returns) * 252
        mu_j_est = jump_returns.mean()
        sigma_j_est = jump_returns.std()
    else: 
        lambda_est, mu_j_est, sigma_j_est = 0.1, 0.0, 0.0
        print("  -> Warning: Not enough jumps detected. Using default jump parameters.")

    # Use the key 'sigma' to match the parameter name in the Merton/Kou models.
    fitted_params = {
        'sigma': sigma_est,
        'lambda': lambda_est,
        'mu_j': mu_j_est,
        'sigma_j': sigma_j_est
    }
    
    print(f"  -> Estimated Historical Params: { {k: f'{v:.4f}' for k,v in fitted_params.items()} }")
    return fitted_params

import pandas as pd
import numpy as np
from scipy.optimize import minimize
from typing import Tuple

def find_atm_options(calls: pd.DataFrame, puts: pd.DataFrame, spot: float) -> pd.DataFrame:
    merged = pd.merge(calls, puts, on=['strike', 'maturity'], suffixes=('_call', '_put'), how='inner')
    if merged.empty: return pd.DataFrame()
    merged['moneyness_dist'] = abs(merged['strike'] - spot)
    atm_indices = merged.groupby('maturity')['moneyness_dist'].idxmin()
    return merged.loc[atm_indices]

def fit_rate_and_dividend(calls: pd.DataFrame, puts: pd.DataFrame, spot: float, r_fixed: float | None = None, q_fixed: float | None = None) -> Tuple[float, float]:
    atm_pairs = find_atm_options(calls, puts, spot)
    if atm_pairs.empty:
        print("Warning: No ATM pairs found. Using default r=0.05, q=0.0.")
        return 0.05, 0.0

    free_param_indices, initial_guess, bounds = [], [], []
    if r_fixed is None:
        free_param_indices.append(0); initial_guess.append(0.05); bounds.append((0.0, 0.15))
    if q_fixed is None:
        free_param_indices.append(1); initial_guess.append(0.01); bounds.append((0.0, 0.10))

    if not free_param_indices: return r_fixed, q_fixed

    def parity_error(x: np.ndarray) -> float:
        r = r_fixed if 0 not in free_param_indices else x[free_param_indices.index(0)]
        q = q_fixed if 1 not in free_param_indices else x[free_param_indices.index(1)]
        parity_rhs = spot * np.exp(-q * atm_pairs['maturity']) - atm_pairs['strike'] * np.exp(-r * atm_pairs['maturity'])
        parity_lhs = atm_pairs['marketPrice_call'] - atm_pairs['marketPrice_put']
        return np.sum((parity_lhs - parity_rhs)**2)

    solution = minimize(fun=parity_error, x0=initial_guess, bounds=bounds, method='L-BFGS-B')
    r_est = r_fixed if 0 not in free_param_indices else solution.x[free_param_indices.index(0)]
    q_est = q_fixed if 1 not in free_param_indices else solution.x[free_param_indices.index(1)]
    print(f"Fitted market params -> r: {r_est:.4f}, q: {q_est:.4f}")
    return float(r_est), float(q_est)


import pandas as pd
import numpy as np

from quantfin.models.base.base_model        import BaseModel
from quantfin.models.bsm                     import BSMModel
from quantfin.atoms.stock                    import Stock
from quantfin.atoms.rate                     import Rate
from quantfin.atoms.option                   import Option, OptionType
from quantfin.techniques.base.base_technique import BaseTechnique
from quantfin.techniques.base.iv_mixin       import IVMixin
from quantfin.calibration.bsm_iv_solver       import BSMIVSolver

class VolatilitySurface:
    def __init__(self, option_data: pd.DataFrame):
        columns_to_keep = ['strike', 'maturity', 'marketPrice', 'optionType', 'expiry']
        self.data = option_data[columns_to_keep].copy()
        self.surface = None
        # Instantiate the fast solver once
        self.iv_solver = BSMIVSolver()

    def _calculate_ivs(self, stock: Stock, rate: Rate, prices_to_invert: pd.Series) -> np.ndarray:
        """Calculates IVs using the fast, vectorized BSM solver."""
        # The solver takes the option data as a DataFrame
        ivs = self.iv_solver.solve(prices_to_invert.values, self.data, stock, rate)
        return ivs

    def calculate_market_iv(self, stock: Stock, rate: Rate) -> 'VolatilitySurface':
        print("Calculating market implied volatility surface...")
        market_ivs = self._calculate_ivs(stock, rate, self.data['marketPrice'])
        self.surface = self.data.copy()
        self.surface['iv'] = market_ivs
        self.surface.dropna(inplace=True)
        self.surface = self.surface[(self.surface['iv'] > 0.01) & (self.surface['iv'] < 2.0)]
        return self

    def calculate_model_iv(self, stock: Stock, rate: Rate, model: BaseModel, technique: BaseTechnique) -> 'VolatilitySurface':
        print(f"Calculating {model.name} implied volatility surface...")
        model_prices = [technique.price(Option(strike=r['strike'], maturity=r['maturity'], option_type=OptionType.CALL if r['optionType'] == 'call' else OptionType.PUT), stock, model, rate, **model.params).price for _, r in self.data.iterrows()]
        model_ivs = self._calculate_ivs(stock, rate, pd.Series(model_prices))
        self.surface = self.data.copy()
        self.surface['iv'] = model_ivs
        self.surface.dropna(inplace=True)
        return self


from quantfin.models.base           import BaseModel
from quantfin.techniques.closed_form import ClosedFormTechnique
from quantfin.techniques.fft         import FFTTechnique
from quantfin.techniques.monte_carlo import MonteCarloTechnique

def select_fastest_technique(model: BaseModel):
    """
    Selects the fastest available pricing technique for a given model.
    The order of preference is: Closed-Form > FFT > Integration > Monte Carlo.
    """
    if model.has_closed_form:
        return ClosedFormTechnique()
    if model.supports_cf:
        return FFTTechnique(n=12)
    if model.supports_sde:
        return MonteCarloTechnique(n_paths=5000, n_steps=50, antithetic=True)
    raise TypeError(f"No suitable pricing technique found for model '{model.name}'")


# src/quantfin/calibration/vectorized_integration_iv.py

from __future__ import annotations
import numpy as np
from scipy import integrate
import pandas as pd
from typing import TYPE_CHECKING

from quantfin.models import BSMModel

if TYPE_CHECKING:
    from quantfin.models import BaseModel
    from quantfin.atoms import Rate

class VectorizedIntegrationIVSolver:
    """
    A high-performance, vectorized Secant method solver for implied volatility
    for any model that supports a characteristic function.
    """
    def __init__(self, max_iter: int = 20, tolerance: float = 1e-7, upper_bound: float = 200.0):
        self.max_iter = max_iter
        self.tolerance = tolerance
        self.upper_bound = upper_bound

    def solve(self, target_prices: np.ndarray, options: pd.DataFrame, model: BaseModel, rate: Rate) -> np.ndarray:
        """
        Calculates implied volatility for an array of options and prices.
        """
        iv0 = np.full_like(target_prices, 0.20)
        iv1 = np.full_like(target_prices, 0.25)

        p0 = self._price_vectorized(iv0, options, model, rate)
        p1 = self._price_vectorized(iv1, options, model, rate)

        f0 = p0 - target_prices
        f1 = p1 - target_prices

        for _ in range(self.max_iter):
            if np.all(np.abs(f1) < self.tolerance):
                break
            denom = f1 - f0
            denom[np.abs(denom) < 1e-12] = 1e-12
            iv_next = iv1 - f1 * (iv1 - iv0) / denom
            iv_next = np.clip(iv_next, 1e-4, 5.0)
            iv0, iv1 = iv1, iv_next
            f0 = f1
            p1 = self._price_vectorized(iv1, options, model, rate)
            f1 = p1 - target_prices
        
        return iv1

    def _price_vectorized(self, iv_vector: np.ndarray, options: pd.DataFrame, model: BaseModel, rate: Rate) -> np.ndarray:
        """
        Internal method to price a vector of options for a given vector of volatilities.
        """
        # CORRECTED LINE: Provide a dummy sigma to pass validation.
        bsm_model = BSMModel(params={"sigma": 0.2})
        prices = np.zeros_like(iv_vector)

        for T, group in options.groupby('maturity'):
            idx = group.index
            S, K = group['spot'].values, group['strike'].values
            q, r = group['dividend'].values, rate.get_rate(T)
            is_call = (group['optionType'].values == 'call')
            
            bsm_model.params['sigma'] = iv_vector[idx]
            phi = bsm_model.cf(t=T, spot=S, r=r, q=q)
            k_log = np.log(K)

            integrand_p2 = lambda u: (np.exp(-1j * u * k_log) * phi(u)).imag / u
            integrand_p1 = lambda u: (np.exp(-1j * u * k_log) * phi(u - 1j)).imag / u

            integral_p2, _ = integrate.quad_vec(integrand_p2, 1e-15, self.upper_bound)
            
            phi_minus_i = phi(-1j)
            phi_minus_i[np.abs(phi_minus_i) < 1e-12] = 1.0
            integral_p1, _ = integrate.quad_vec(integrand_p1, 1e-15, self.upper_bound)
            
            P1 = 0.5 + integral_p1 / (np.pi * np.real(phi_minus_i))
            P2 = 0.5 + integral_p2 / np.pi

            call_prices = S * np.exp(-q * T) * P1 - K * np.exp(-r * T) * P2
            put_prices = K * np.exp(-r * T) * (1 - P2) - S * np.exp(-q * T) * (1 - P1)
            
            prices[idx] = np.where(is_call, call_prices, put_prices)
            
        return prices

